{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pydantic Data Flow\n",
    "\n",
    "Pydantic data flow utelizes the capabilities of the pydantic library, to secure the data flows in circular pipeline.\n",
    "You can imagine this as a live database, that keeps the information of data between pipeline stations.\n",
    "\n",
    "## Why do we want this?\n",
    "\n",
    "In a normal instance of a pytorch script or program, the dataflow is mostly a simple input/output with a sequential flow of instructions.\n",
    "In this case just loading the data is satisfying, and the job will complete just fine, probably.\n",
    "\n",
    "But what if we have a dataflow which makes it necessary to save manipulated from time to time on the disk?\n",
    "In example with \"BoxSup\" we update the labels, and use them in the training afterwards.\n",
    "To do this in just one step might exceed the given memory on the machine.\n",
    "\n",
    "To solve this we can save the data between the steps on the disk.\n",
    "But how can we validate the data is on the right spot and cleanup in between?\n",
    "\n",
    "For this scenario we implement different dataclasses, which provide the necessary information and validate them with the pydantic's implementation.\n",
    "\n",
    "## Analysis how normal Dataloading works\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
