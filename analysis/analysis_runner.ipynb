{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import csv\n",
    "from scipy.stats import skewnorm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_csv(dur):\n",
    "    with open(f\"../analysis/runner_{dur}sec.csv\", newline='') as csvfile:\n",
    "        benchreader = csv.reader(csvfile, delimiter=\",\")\n",
    "        \n",
    "        headings = next(benchreader) \n",
    "\n",
    "        run_dict = {\n",
    "            f\"runs_{dur}sec_mean\": [],\n",
    "            f\"runs_{dur}sec_stddev\": [],\n",
    "            f\"runs_{dur}sec_median\": [],\n",
    "            f\"runs_{dur}sec_min\": [],\n",
    "            f\"runs_{dur}sec_max\": []\n",
    "        }\n",
    "        \n",
    "        batches = 19\n",
    "        correctur_value = dur*batches\n",
    "        \n",
    "        for row in benchreader:\n",
    "            run_dict[f\"runs_{dur}sec_mean\"].append(float(row[1]) - correctur_value)\n",
    "            run_dict[f\"runs_{dur}sec_stddev\"].append(float(row[2]))\n",
    "            run_dict[f\"runs_{dur}sec_median\"].append(float(row[3]) - correctur_value)\n",
    "            run_dict[f\"runs_{dur}sec_min\"].append(float(row[6]) - correctur_value)\n",
    "            run_dict[f\"runs_{dur}sec_max\"].append(float(row[7]) - correctur_value)\n",
    "        \n",
    "        run_dict[f\"runs_{dur}sec_mean\"] = np.array(run_dict[f\"runs_{dur}sec_mean\"])\n",
    "        run_dict[f\"runs_{dur}sec_stddev\"] = np.array(run_dict[f\"runs_{dur}sec_stddev\"])\n",
    "        run_dict[f\"runs_{dur}sec_median\"] = np.array(run_dict[f\"runs_{dur}sec_median\"])\n",
    "        run_dict[f\"runs_{dur}sec_min\"] = np.array(run_dict[f\"runs_{dur}sec_min\"])\n",
    "        run_dict[f\"runs_{dur}sec_max\"] = np.array(run_dict[f\"runs_{dur}sec_max\"])\n",
    "        \n",
    "    return headings, run_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runs_per_epoch = 19\n",
    "\n",
    "num_worker = np.array(range(2,20,2))\n",
    "print(num_worker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h, runs_0sec = load_csv(0)\n",
    "h, runs_1sec = load_csv(1)\n",
    "h, runs_2sec = load_csv(2)\n",
    "h, runs_5sec = load_csv(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparison of Train Time for Dataloader Worker\n",
    "\n",
    "The dataloader includes an argument `num_worker` which allows multiple processes to load data.\n",
    "Depending of the time consumpted by the training process the dataloading process could vary, based on `num_worker`.\n",
    "This Analysis shows the results of four different Benchmarks, which are generated with `hyperbench`, a high performance benchmarktool written in rust[1].\n",
    "\n",
    "[1]: [hyperfine](https://github.com/sharkdp/hyperfine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(num_worker, runs_0sec[\"runs_0sec_mean\"], marker=\"X\", color=\"blue\")\n",
    "plt.plot(num_worker, runs_1sec[\"runs_1sec_mean\"], marker=\"X\", color=\"magenta\")\n",
    "plt.plot(num_worker, runs_2sec[\"runs_2sec_mean\"], marker=\"X\", color=\"green\")\n",
    "plt.plot(num_worker, runs_5sec[\"runs_5sec_mean\"], marker=\"X\", color=\"red\")\n",
    "plt.xlabel(\"Num Worker\")\n",
    "plt.ylabel(\"Mean Time per Dataloading per Epoch [s]\")\n",
    "plt.legend([\n",
    "    \"Training 0 sec (simulated)\",\n",
    "    \"Training 1 sec (simulated)\",\n",
    "    \"Training 2 sec (simulated)\",\n",
    "    \"Training 5 sec (simulated)\"\n",
    "])\n",
    "plt.title(\"Worker Time Consumption based on Train Time\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.errorbar(\n",
    "    num_worker, runs_0sec[\"runs_0sec_mean\"],\n",
    "    [\n",
    "        runs_0sec[\"runs_0sec_mean\"] -  runs_0sec[\"runs_0sec_min\"],\n",
    "        runs_0sec[\"runs_0sec_max\"]-  runs_0sec[\"runs_0sec_mean\"]\n",
    "    ], marker=\"X\", color=\"blue\"\n",
    ")\n",
    "plt.errorbar(\n",
    "    num_worker, runs_1sec[\"runs_1sec_mean\"],\n",
    "    [\n",
    "        runs_1sec[\"runs_1sec_mean\"] -  runs_1sec[\"runs_1sec_min\"],\n",
    "        runs_1sec[\"runs_1sec_max\"]-  runs_1sec[\"runs_1sec_mean\"]\n",
    "    ], marker=\"X\", color=\"magenta\"\n",
    ")\n",
    "plt.errorbar(\n",
    "    num_worker, runs_2sec[\"runs_2sec_mean\"],\n",
    "    [\n",
    "        runs_2sec[\"runs_2sec_mean\"] -  runs_2sec[\"runs_2sec_min\"],\n",
    "        runs_2sec[\"runs_2sec_max\"]-  runs_2sec[\"runs_2sec_mean\"]\n",
    "    ], marker=\"X\", color=\"green\"\n",
    ")\n",
    "plt.errorbar(\n",
    "    num_worker, runs_5sec[\"runs_5sec_mean\"],\n",
    "    [\n",
    "        runs_5sec[\"runs_5sec_mean\"] -  runs_5sec[\"runs_5sec_min\"],\n",
    "        runs_5sec[\"runs_5sec_max\"]-  runs_5sec[\"runs_5sec_mean\"]\n",
    "    ], marker=\"X\", color=\"red\")\n",
    "plt.xlabel(\"Num Worker\")\n",
    "plt.ylabel(\"Mean Time per Dataloading per Epoch [s]\")\n",
    "plt.legend([\n",
    "    \"Training 0 sec (simulated)\",\n",
    "    \"Training 1 sec (simulated)\",\n",
    "    \"Training 2 sec (simulated)\",\n",
    "    \"Training 5 sec (simulated)\"\n",
    "])\n",
    "plt.title(\"Worker Time Consumption based on Train Time with errors\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mean results\n",
    "\n",
    "The values of the benchmark are corrected by the amount of the simulated training.\n",
    "The simulated training time is simulated by a simple `sleep(duration)`.\n",
    "The graph shows that with rising training time consumption the number of necessary workers is reduced.\n",
    "If the training tooks 0 seconds the amount of necessary workers isn't reached with 18 workers.\n",
    "This scenario is very unlikly.\n",
    "With the training tooks 5 seconds it is shown, that already 4 worker  satisfy a minimum value, which only rises with rising number of workers.\n",
    "With 2 seconds the sweetspot is reached at 8 Workers and with 1 second at 16 Workers.\n",
    "Based on this small analysis we can formulate perfect value of `num_worker`:\n",
    "\n",
    "For every halfing of training time we estimate a double of necessary worker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(num_worker, runs_0sec[\"runs_0sec_median\"], marker=\"o\", color=\"blue\")\n",
    "plt.plot(num_worker, runs_1sec[\"runs_1sec_median\"], marker=\"o\", color=\"magenta\")\n",
    "plt.plot(num_worker, runs_2sec[\"runs_2sec_median\"], marker=\"o\", color=\"green\")\n",
    "plt.plot(num_worker, runs_5sec[\"runs_5sec_median\"], marker=\"o\", color=\"red\")\n",
    "plt.plot(num_worker, runs_0sec[\"runs_0sec_mean\"], marker=\"2\", color=\"lightblue\", linestyle=\"dashdot\")\n",
    "plt.plot(num_worker, runs_1sec[\"runs_1sec_mean\"], marker=\"2\", color=\"plum\", linestyle=\"dashdot\")\n",
    "plt.plot(num_worker, runs_2sec[\"runs_2sec_mean\"], marker=\"2\", color=\"limegreen\", linestyle=\"dashdot\")\n",
    "plt.plot(num_worker, runs_5sec[\"runs_5sec_mean\"], marker=\"2\", color=\"lightcoral\", linestyle=\"dashdot\")\n",
    "plt.xlabel(\"Num Worker\")\n",
    "plt.ylabel(\"Mean Time per Dataloading per Epoch [s]\")\n",
    "plt.legend([\n",
    "    \"Training 0 sec (simulated)\",\n",
    "    \"Training 1 sec (simulated)\",\n",
    "    \"Training 2 sec (simulated)\",\n",
    "    \"Training 5 sec (simulated)\"\n",
    "])\n",
    "plt.title(\"Worker Time Consumption based on Train Time\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_0 = np.abs([\"runs_0sec_mediruns_0secan\"] -runs_0sec[\"runs_0sec_mean\"])\n",
    "diff_1 = np.abs(runs_1sec[\"runs_1sec_median\"] -runs_1sec[\"runs_1sec_mean\"])\n",
    "diff_2 = np.abs(runs_2sec[\"runs_2sec_median\"] -runs_2sec[\"runs_2sec_mean\"])\n",
    "diff_5 = np.abs(runs_5sec[\"runs_5sec_median\"] -runs_5sec[\"runs_5sec_mean\"])\n",
    "\n",
    "print(\"Diff 0: \", diff_0)\n",
    "print(\"Diff 1: \", diff_1)\n",
    "print(\"Diff 2: \", diff_2)\n",
    "print(\"Diff 5: \", diff_5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Further, we analyzed the absolute difference between mean and median and could only notice a difference above one second for the 2 second run.\n",
    "By this statement we assume that we are handling mostly skewed normal distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_skew(run_dict, dur):\n",
    "    xi = np.array([\n",
    "        run_dict[f\"runs_{dur}sec_median\"],\n",
    "        run_dict[f\"runs_{dur}sec_min\"],\n",
    "        run_dict[f\"runs_{dur}sec_max\"]\n",
    "    ]) \n",
    "    mu = run_dict[f\"runs_{dur}sec_mean\"]\n",
    "    sig = run_dict[f\"runs_{dur}sec_stddev\"]\n",
    "    return np.sum(np.power((xi - mu) / sig, 3),0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skew_0sec = calc_skew(runs_0sec, 0)\n",
    "skew_1sec = calc_skew(runs_1sec, 1)\n",
    "skew_2sec = calc_skew(runs_2sec, 2)\n",
    "skew_5sec = calc_skew(runs_5sec, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha0 = skew_0sec[0]\n",
    "mu0 = runs_0sec[\"runs_0sec_mean\"][0]\n",
    "sigma0 = runs_0sec[\"runs_0sec_stddev\"][0]\n",
    "\n",
    "y0 = skewnorm.rvs(alpha0, mu0, sigma0, size=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha1 = skew_1sec[0]\n",
    "mu1 = runs_1sec[\"runs_1sec_mean\"][0]\n",
    "sigma1 = runs_1sec[\"runs_1sec_stddev\"][0]\n",
    "\n",
    "y1 = skewnorm.rvs(alpha1, mu1, sigma1, size=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha2 = skew_2sec[0]\n",
    "mu2 = runs_2sec[\"runs_2sec_mean\"][0]\n",
    "sigma2 = runs_2sec[\"runs_2sec_stddev\"][0]\n",
    "\n",
    "y2 = skewnorm.rvs(alpha2, mu2, sigma2, size=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha5 = skew_5sec[0]\n",
    "mu5 = runs_5sec[\"runs_5sec_mean\"][0]\n",
    "sigma5 = runs_5sec[\"runs_5sec_stddev\"][0]\n",
    "\n",
    "y5 = skewnorm.rvs(alpha5, mu5, sigma5, size=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(y0, bins=50, density=True, color=\"blue\")\n",
    "plt.hist(y1, bins=50, density=True, color=\"magenta\")\n",
    "plt.hist(y2, bins=50, density=True, color=\"green\")\n",
    "plt.hist(y5, bins=50, density=True, color=\"red\")\n",
    "plt.xlabel('Value')\n",
    "plt.ylabel('Probability density')\n",
    "plt.title('Skew normal distribution')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
